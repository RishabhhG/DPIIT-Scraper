import requests
import json
import time
from typing import List, Dict, Any
import logging
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure, DuplicateKeyError
from datetime import datetime
import os

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class StartupDataExtractor:
    def __init__(self, mongo_uri: str = None, db_name: str = "startup_data"):
        self.base_url = "https://api.startupindia.gov.in/sih/api"
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/json',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # MongoDB configuration
        self.mongo_uri = mongo_uri or os.getenv('MONGODB_URI', 'mongodb+srv://Rishabh:8080@cluster0.53pnc.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0')
        self.db_name = db_name
        self.client = None
        self.db = None
        self.collections = {
            'profiles': 'startup_profiles',
            'summary': 'extraction_summary',
            'errors': 'extraction_errors'
        }
        
        # Initialize MongoDB connection
        self._init_mongodb()
        
    def _init_mongodb(self):
        """Initialize MongoDB connection and create collections"""
        try:
            self.client = MongoClient(self.mongo_uri, serverSelectionTimeoutMS=5000)
            # Test connection
            self.client.admin.command('ping')
            self.db = self.client[self.db_name]
            
            # Create collections if they don't exist
            for collection_name in self.collections.values():
                if collection_name not in self.db.list_collection_names():
                    self.db.create_collection(collection_name)
            
            # Create indexes for better query performance
            self.db[self.collections['profiles']].create_index("profile_id", unique=True)
            self.db[self.collections['profiles']].create_index("page")
            self.db[self.collections['profiles']].create_index("processing_info.timestamp")
            self.db[self.collections['profiles']].create_index("processing_info.success")
            
            logger.info(f"Successfully connected to MongoDB: {self.db_name}")
            
        except ConnectionFailure as e:
            logger.error(f"Failed to connect to MongoDB: {e}")
            raise
        except Exception as e:
            logger.error(f"Error initializing MongoDB: {e}")
            raise
    
    def close_connection(self):
        """Close MongoDB connection"""
        if self.client:
            self.client.close()
            logger.info("MongoDB connection closed")
        
    def get_startup_profiles(self, page: int) -> List[Dict[str, Any]]:
        """
        Fetch startup profiles for a given page and return complete profile data
        """
        url = f"{self.base_url}/noauth/search/profiles"
        
        payload = {
            "badges": [],
            "cities": [],
            "dpiitRecogniseUser": True,
            "focusSector": False,
            "industries": [],
            "internationalUser": False,
            "page": page,
            "query": "",
            "roles": ["Startup"],
            "sectors": [],
            "sort": {
                "orders": [
                    {
                        "field": "registeredOn",
                        "direction": "DESC"
                    }
                ]
            },
            "stages": [],
            "states": ["5f48ce592a9bb065cdf9fb3b"]
        }
        
        try:
            response = self.session.post(url, json=payload)
            response.raise_for_status()
            
            data = response.json()
            
            # Return complete profile data from the search
            profiles = []
            if 'content' in data:
                profiles = data['content']
            
            logger.info(f"Page {page}: Found {len(profiles)} profiles")
            return profiles
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching profiles for page {page}: {e}")
            return []
        except json.JSONDecodeError as e:
            logger.error(f"Error parsing JSON response for page {page}: {e}")
            return []
    
    def get_profile_details(self, profile_id: str) -> Dict[str, Any]:
        """
        Fetch detailed profile information for a given profile ID
        """
        url = f"{self.base_url}/common/replica/user/profile/{profile_id}"
        
        try:
            response = self.session.get(url)
            response.raise_for_status()
            
            data = response.json()
            logger.info(f"Successfully fetched details for profile {profile_id}")
            return data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching profile details for {profile_id}: {e}")
            return {}
        except json.JSONDecodeError as e:
            logger.error(f"Error parsing JSON response for profile {profile_id}: {e}")
            return {}
    
    def get_cin_info(self, cin: str) -> Dict[str, Any]:
        """
        Fetch CIN information and return complete data
        """
        url = f"{self.base_url}/noauth/dpiit/services/cin/info"
        params = {"cin": cin}
        
        try:
            response = self.session.get(url, params=params)
            response.raise_for_status()
            
            data = response.json()
            logger.info(f"Successfully fetched CIN info for {cin}")
            return data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching CIN info for {cin}: {e}")
            return {}
        except json.JSONDecodeError as e:
            logger.error(f"Error parsing JSON response for CIN {cin}: {e}")
            return {}
    
    def extract_cin_from_profile(self, profile_data: Dict[str, Any]) -> str:
        """
        Extract CIN from profile data based on the sample structure provided
        """
        try:
            # Based on the sample response structure: user.startup.cin
            if 'user' in profile_data and 'startup' in profile_data['user']:
                cin = profile_data['user']['startup'].get('cin', '')
                if cin:
                    return cin
            
            # Fallback: Look for CIN in various possible locations
            cin_fields = ['cin', 'CIN', 'companyIdentificationNumber']
            
            for field in cin_fields:
                if field in profile_data:
                    return profile_data[field]
            
            # Check nested objects
            if 'company' in profile_data:
                for field in cin_fields:
                    if field in profile_data['company']:
                        return profile_data['company'][field]
            
            if 'businessDetails' in profile_data:
                for field in cin_fields:
                    if field in profile_data['businessDetails']:
                        return profile_data['businessDetails'][field]
            
            if 'startup' in profile_data:
                for field in cin_fields:
                    if field in profile_data['startup']:
                        return profile_data['startup'][field]
                        
        except (KeyError, TypeError) as e:
            logger.warning(f"Error extracting CIN from profile data: {e}")
        
        return ""
    
    def save_profile_to_mongodb(self, profile_data: Dict[str, Any]) -> bool:
        """
        Save individual profile data to MongoDB
        """
        try:
            # Add MongoDB-specific fields
            profile_data['_id'] = profile_data['profile_id']  # Use profile_id as _id
            profile_data['created_at'] = datetime.utcnow()
            profile_data['updated_at'] = datetime.utcnow()
            
            # Insert or update the document
            result = self.db[self.collections['profiles']].replace_one(
                {'_id': profile_data['profile_id']},
                profile_data,
                upsert=True
            )
            
            if result.upserted_id or result.modified_count > 0:
                logger.info(f"Successfully saved profile {profile_data['profile_id']} to MongoDB")
                return True
            else:
                logger.warning(f"No changes made for profile {profile_data['profile_id']}")
                return False
                
        except DuplicateKeyError:
            logger.warning(f"Profile {profile_data['profile_id']} already exists, updating...")
            try:
                # Update existing document
                profile_data['updated_at'] = datetime.utcnow()
                result = self.db[self.collections['profiles']].update_one(
                    {'_id': profile_data['profile_id']},
                    {'$set': profile_data}
                )
                return result.modified_count > 0
            except Exception as e:
                logger.error(f"Error updating profile {profile_data['profile_id']}: {e}")
                return False
        except Exception as e:
            logger.error(f"Error saving profile {profile_data['profile_id']} to MongoDB: {e}")
            # Save error details
            self._save_error(profile_data['profile_id'], str(e), 'save_profile')
            return False
    
    def _save_error(self, profile_id: str, error_message: str, operation: str):
        """Save error information to MongoDB"""
        try:
            error_doc = {
                'profile_id': profile_id,
                'error_message': error_message,
                'operation': operation,
                'timestamp': datetime.utcnow()
            }
            self.db[self.collections['errors']].insert_one(error_doc)
        except Exception as e:
            logger.error(f"Failed to save error to MongoDB: {e}")
    
    def process_pages(self, start_page: int = 1, end_page: int = 5, delay: float = 1.0) -> Dict[str, Any]:
        """
        Process multiple pages and extract all data from all three APIs
        Save directly to MongoDB instead of returning all data
        
        Args:
            start_page: Starting page number
            end_page: Ending page number (inclusive)
            delay: Delay between API calls to avoid rate limiting
        
        Returns:
            Dictionary with processing statistics
        """
        stats = {
            'total_profiles': 0,
            'successful_saves': 0,
            'failed_saves': 0,
            'profiles_with_cin': 0,
            'start_time': datetime.utcnow(),
            'pages_processed': []
        }
        
        logger.info(f"Starting data extraction from page {start_page} to {end_page}")
        
        for page in range(start_page, end_page + 1):
            logger.info(f"Processing page {page}")
            page_stats = {'page': page, 'profiles': 0, 'successful': 0, 'failed': 0}
            
            # Step 1: Get all profile data for this page (1st API)
            profiles = self.get_startup_profiles(page)
            
            if not profiles:
                logger.warning(f"No profiles found for page {page}")
                stats['pages_processed'].append(page_stats)
                continue
            
            # Step 2: Process each profile
            for profile in profiles:
                profile_id = profile.get('id', '')
                if not profile_id:
                    logger.warning("Profile missing ID, skipping")
                    continue
                
                logger.info(f"Processing profile: {profile_id}")
                stats['total_profiles'] += 1
                page_stats['profiles'] += 1
                
                # Initialize the complete data structure
                complete_data = {
                    'profile_id': profile_id,
                    'page': page,
                    'search_profile_data': profile,  # Data from 1st API
                    'detailed_profile_data': {},     # Data from 2nd API
                    'cin_data': {},                  # Data from 3rd API
                    'processing_info': {
                        'timestamp': time.time(),
                        'success': False,
                        'errors': []
                    }
                }
                
                time.sleep(delay)  # Rate limiting
                
                # Step 3: Get detailed profile information (2nd API)
                detailed_profile = self.get_profile_details(profile_id)
                
                if detailed_profile:
                    complete_data['detailed_profile_data'] = detailed_profile
                    
                    # Step 4: Extract CIN from detailed profile
                    cin = self.extract_cin_from_profile(detailed_profile)
                    
                    if cin:
                        logger.info(f"Found CIN: {cin} for profile {profile_id}")
                        
                        time.sleep(delay)  # Rate limiting
                        
                        # Step 5: Get CIN information (3rd API)
                        cin_info = self.get_cin_info(cin)
                        
                        if cin_info:
                            complete_data['cin_data'] = cin_info
                            complete_data['processing_info']['success'] = True
                            stats['profiles_with_cin'] += 1
                            logger.info(f"Successfully collected all data for profile {profile_id}")
                        else:
                            complete_data['processing_info']['errors'].append("Failed to fetch CIN data")
                            logger.warning(f"Failed to fetch CIN data for {cin}")
                    else:
                        complete_data['processing_info']['errors'].append("CIN not found in profile data")
                        logger.warning(f"No CIN found for profile {profile_id}")
                else:
                    complete_data['processing_info']['errors'].append("Failed to fetch detailed profile data")
                    logger.warning(f"Failed to fetch detailed profile for {profile_id}")
                
                # Save to MongoDB immediately
                if self.save_profile_to_mongodb(complete_data):
                    stats['successful_saves'] += 1
                    page_stats['successful'] += 1
                else:
                    stats['failed_saves'] += 1
                    page_stats['failed'] += 1
            
            stats['pages_processed'].append(page_stats)
            logger.info(f"Completed page {page}. Profiles processed: {page_stats['profiles']}, "
                       f"Successful saves: {page_stats['successful']}, Failed saves: {page_stats['failed']}")
        
        stats['end_time'] = datetime.utcnow()
        stats['duration'] = (stats['end_time'] - stats['start_time']).total_seconds()
        
        return stats
    
    def save_summary_to_mongodb(self, stats: Dict[str, Any]):
        """
        Save processing summary to MongoDB
        """
        try:
            # Get sample contacts from saved profiles
            sample_contacts = []
            cursor = self.db[self.collections['profiles']].find(
                {'processing_info.success': True, 'cin_data': {'$exists': True, '$ne': {}}},
                limit=10
            )
            
            for profile in cursor:
                contact_sample = {
                    'profile_id': profile['profile_id'],
                    'company_name': '',
                    'email': profile.get('cin_data', {}).get('email', ''),
                    'phone': profile.get('cin_data', {}).get('registeredContactNo', ''),
                    'cin': ''
                }
                
                # Try to get company name from detailed profile
                if profile.get('detailed_profile_data', {}).get('user', {}).get('startup', {}).get('name'):
                    contact_sample['company_name'] = profile['detailed_profile_data']['user']['startup']['name']
                
                # Try to get CIN
                if profile.get('detailed_profile_data', {}).get('user', {}).get('startup', {}).get('cin'):
                    contact_sample['cin'] = profile['detailed_profile_data']['user']['startup']['cin']
                
                sample_contacts.append(contact_sample)
            
            # Create summary document
            summary_doc = {
                '_id': f"summary_{int(time.time())}",
                'extraction_stats': stats,
                'sample_contacts': sample_contacts,
                'created_at': datetime.utcnow()
            }
            
            # Save summary
            self.db[self.collections['summary']].insert_one(summary_doc)
            logger.info("Summary saved to MongoDB")
            
        except Exception as e:
            logger.error(f"Error saving summary to MongoDB: {e}")
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """Get statistics about the MongoDB collections"""
        try:
            profiles_count = self.db[self.collections['profiles']].count_documents({})
            successful_count = self.db[self.collections['profiles']].count_documents(
                {'processing_info.success': True}
            )
            with_cin_count = self.db[self.collections['profiles']].count_documents(
                {'cin_data': {'$exists': True, '$ne': {}}}
            )
            errors_count = self.db[self.collections['errors']].count_documents({})
            
            return {
                'total_profiles_in_db': profiles_count,
                'successful_profiles': successful_count,
                'profiles_with_cin_data': with_cin_count,
                'total_errors': errors_count
            }
        except Exception as e:
            logger.error(f"Error getting collection stats: {e}")
            return {}

def main():
    """
    Main function to run the data extraction
    """
    # Configuration - Modify these values as needed
    START_PAGE = 2
    END_PAGE = 2  # Adjust based on your needs
    DELAY_BETWEEN_CALLS = 2.0  # Seconds between API calls
    
    # MongoDB configuration
    MONGODB_URI = os.getenv('MONGODB_URI', 'mongodb+srv://Rishabh:8080@cluster0.53pnc.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0')
    DATABASE_NAME = "startup_data"
    
    # Initialize extractor
    extractor = None
    
    try:
        extractor = StartupDataExtractor(mongo_uri=MONGODB_URI, db_name=DATABASE_NAME)
        
        # Extract data and save to MongoDB
        stats = extractor.process_pages(
            start_page=START_PAGE,
            end_page=END_PAGE,
            delay=DELAY_BETWEEN_CALLS
        )
        
        # Display summary
        logger.info(f"Data extraction completed!")
        logger.info(f"Total profiles processed: {stats['total_profiles']}")
        logger.info(f"Successfully saved to MongoDB: {stats['successful_saves']}")
        logger.info(f"Failed saves: {stats['failed_saves']}")
        logger.info(f"Profiles with CIN data: {stats['profiles_with_cin']}")
        logger.info(f"Processing duration: {stats['duration']:.2f} seconds")
        
        # Save summary to MongoDB
        extractor.save_summary_to_mongodb(stats)
        
        # Display database statistics
        db_stats = extractor.get_collection_stats()
        if db_stats:
            logger.info("Current database statistics:")
            for key, value in db_stats.items():
                logger.info(f"  {key}: {value}")
        
    except KeyboardInterrupt:
        logger.info("Process interrupted by user")
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
    finally:
        if extractor:
            extractor.close_connection()

if __name__ == "__main__":
    main()